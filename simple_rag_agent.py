#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„ RAG æ™ºèƒ½ä½“ - ä½¿ç”¨ LangChain create_agent
åŸºäº LangChain æœ€æ–°æœ€ä½³å®è·µ
å‚è€ƒ: https://docs.langchain.com/oss/python/langchain/rag

åŠŸèƒ½ï¼š
- ä½¿ç”¨ create_agent åˆ›å»ºæ™ºèƒ½ä½“
- é€šè¿‡å·¥å…·ï¼ˆtoolï¼‰æ£€ç´¢å‘é‡æ•°æ®åº“
- å›ç­”å…³äºæ•°æ®åº“ä¸šåŠ¡éœ€æ±‚å’Œè¡¨ç»“æ„çš„é—®é¢˜
"""

import os
import sys
from pathlib import Path
from typing import Any

from dotenv import load_dotenv
load_dotenv()

# LangChain æ ¸å¿ƒç»„ä»¶

from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain.agents import create_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# API é…ç½®
OPENAI_API_KEY = os.getenv("openrouter_api_key") or os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("url_openrouter", "https://api.openai.com/v1")

if not OPENAI_API_KEY:
    print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    sys.exit(1)


class SimpleRAGAgent:
    """
    ç®€å•çš„ RAG æ™ºèƒ½ä½“
    ä½¿ç”¨ LangChain create_agent å’Œå‘é‡æ•°æ®åº“
    """
    
    def __init__(
        self,
        persist_directory: str = "./chroma_db",
        collection_name: str = "database_knowledge",
        model_name: str = "anthropic/claude-opus-4.5",
        temperature: float = 0
    ):
        """
        åˆå§‹åŒ– RAG æ™ºèƒ½ä½“
        
        Args:
            persist_directory: å‘é‡æ•°æ®åº“ç›®å½•
            collection_name: é›†åˆåç§°
            model_name: LLM æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ0=ç¡®å®šæ€§ï¼Œ1=åˆ›é€ æ€§ï¼‰
        """
        self.persist_directory = Path(persist_directory)
        self.collection_name = collection_name
        
        print("ğŸš€ åˆå§‹åŒ– RAG æ™ºèƒ½ä½“...")
        
        # 1. åˆå§‹åŒ– Embeddings
        print("  ğŸ“Š åŠ è½½ Embedding æ¨¡å‹...")
        embedding_kwargs = {
            "model": "text-embedding-3-large",
            "api_key": OPENAI_API_KEY,
        }
        if "openrouter" in OPENAI_BASE_URL.lower():
            embedding_kwargs["base_url"] = OPENAI_BASE_URL
        
        self.embeddings = OpenAIEmbeddings(**embedding_kwargs)
        
        # 2. åŠ è½½å‘é‡æ•°æ®åº“
        print(f"  ğŸ’¾ åŠ è½½å‘é‡æ•°æ®åº“: {persist_directory}")
        self.vectorstore = self._load_vectorstore()
        
        if not self.vectorstore:
            raise ValueError("æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“ï¼Œè¯·å…ˆè¿è¡Œ build_knowledge_base.py")
        
        # 3. åˆå§‹åŒ– LLM
        print(f"  ğŸ¤– åˆå§‹åŒ– LLM: {model_name}")
        llm_kwargs = {
            "model": model_name,
            "temperature": temperature,
            "api_key": OPENAI_API_KEY,
        }
        if "openrouter" in OPENAI_BASE_URL.lower():
            llm_kwargs["base_url"] = OPENAI_BASE_URL
        
        self.llm = ChatOpenAI(**llm_kwargs)
        
        # 4. åˆ›å»ºæ£€ç´¢å·¥å…·
        print("  ğŸ› ï¸  åˆ›å»ºæ£€ç´¢å·¥å…·...")
        self.tools = [self._create_retrieval_tool()]
        
        # 5. åˆ›å»ºæ™ºèƒ½ä½“
        print(" åˆ›å»ºæ™ºèƒ½ä½“...")
        self.agent = self._create_agent()
        
        print(" RAG æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆï¼\n")
    
    def _load_vectorstore(self) -> Chroma:
        """åŠ è½½å‘é‡æ•°æ®åº“"""
        try:
            vectorstore = Chroma(
                collection_name=self.collection_name,
                embedding_function=self.embeddings,
                persist_directory=str(self.persist_directory)
            )
            doc_count = vectorstore._collection.count()
            print(f"  æˆåŠŸåŠ è½½ {doc_count} ä¸ªæ–‡æ¡£")
            return vectorstore
        except Exception as e:
            print(f"  åŠ è½½å¤±è´¥: {e}")
            return None
    
    def _create_retrieval_tool(self):
        """
        åˆ›å»ºæ£€ç´¢å·¥å…·
        å‚è€ƒ: https://docs.langchain.com/oss/python/langchain/rag
        """
        @tool
        def retrieve_database_knowledge(query: str) -> str:
            """
            ä»æ•°æ®åº“çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚
            
            è¿™ä¸ªå·¥å…·å¯ä»¥å›ç­”å…³äºï¼š
            - æ•°æ®åº“è¡¨ç»“æ„å’Œå­—æ®µä¿¡æ¯
            - SQLæŸ¥è¯¢å’Œä¸šåŠ¡éœ€æ±‚
            - è¡¨ä¹‹é—´çš„å…³ç³»
            
            Args:
                query: è¦æ£€ç´¢çš„é—®é¢˜æˆ–å…³é”®è¯
                
            Returns:
                æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
            """
            try:
                # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
                retrieved_docs = self.vectorstore.similarity_search(query, k=3)
                
                if not retrieved_docs:
                    return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
                
                # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
                result_parts = []
                for i, doc in enumerate(retrieved_docs, 1):
                    metadata = doc.metadata
                    doc_type = metadata.get('type', 'æœªçŸ¥ç±»å‹')
                    
                    if doc_type == 'business_query':
                        title = f"æŸ¥è¯¢ #{metadata.get('query_id')}: {metadata.get('query_name')}"
                        tables = metadata.get('tables', '')
                        if tables:
                            title += f" (æ¶‰åŠè¡¨: {tables})"
                    else:
                        table_name = metadata.get('table_name', 'æœªçŸ¥è¡¨')
                        table_comment = metadata.get('table_comment', '')
                        title = f"è¡¨ç»“æ„: {table_name} - {table_comment}"
                    
                    result_parts.append(f"ã€æ£€ç´¢ç»“æœ {i}ã€‘{title}\n{doc.page_content}\n")
                
                return "\n".join(result_parts)
                
            except Exception as e:
                return f"æ£€ç´¢å‡ºé”™: {str(e)}"
        
        return retrieve_database_knowledge
    
    def _create_agent(self):
        """
        åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆä½¿ç”¨ LangChain v1.x æ–¹å¼ï¼‰
        """
        # åˆ›å»ºæ™ºèƒ½ä½“
        agent = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åº“åŠ©æ‰‹ï¼Œè´Ÿè´£å›ç­”å…³äºæ•°æ®åº“è¡¨ç»“æ„å’ŒSQLæŸ¥è¯¢çš„é—®é¢˜ã€‚

ä½ çš„èŒè´£ï¼š
1. ä½¿ç”¨æ£€ç´¢å·¥å…· (retrieve_database_knowledge) æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯
2. åŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯å‡†ç¡®å›ç­”ç”¨æˆ·é—®é¢˜
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œå¯ä»¥å¤šæ¬¡ä½¿ç”¨å·¥å…·æ£€ç´¢
4. ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„ä¸­æ–‡å›ç­”

æ³¨æ„äº‹é¡¹ï¼š
- å¯¹äºè¡¨ç»“æ„é—®é¢˜ï¼Œè¯¦ç»†è¯´æ˜å­—æ®µå«ä¹‰
- å¯¹äºSQLé—®é¢˜ï¼Œè§£é‡Šä¸šåŠ¡éœ€æ±‚å’Œå®ç°é€»è¾‘
- å¦‚æœæ£€ç´¢ä¸åˆ°ä¿¡æ¯ï¼Œè¯šå®å‘ŠçŸ¥ç”¨æˆ·"""
        )

        return agent
    
    def chat(self, question: str) -> str:
        """
        ä¸æ™ºèƒ½ä½“å¯¹è¯
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            æ™ºèƒ½ä½“å›ç­”
        """
        try:
            print(f"å¼€å§‹è°ƒç”¨æ™ºèƒ½ä½“")
            response = self.agent.invoke({"messages": [{"role": "user", "content": question}]})
            last_message = response["messages"][-1]  
            answer = last_message.content
            return answer
        except Exception as e:
            return f"å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def stream_chat(self, question: str):
        """
        æµå¼å¯¹è¯ï¼ˆæ‰“å°ä¸­é—´æ­¥éª¤ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        """
        print(f"\n{'='*70}")
        print(f"ğŸ’¬ ç”¨æˆ·é—®é¢˜: {question}")
        print(f"{'='*70}\n")
        
        try:
            for step in self.agent.stream({"input": question}):
                # æ‰“å°ä¸­é—´æ­¥éª¤
                if "actions" in step:
                    for action in step["actions"]:
                        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {action.tool}")
                        print(f"ğŸ“ å·¥å…·è¾“å…¥: {action.tool_input}")
                        print()
                
                if "steps" in step:
                    for step_detail in step["steps"]:
                        print(f"ğŸ“Š å·¥å…·è¾“å‡º:")
                        output = step_detail.observation
                        # é™åˆ¶è¾“å‡ºé•¿åº¦
                        if len(output) > 500:
                            output = output[:500] + "...\n[è¾“å‡ºå·²æˆªæ–­]"
                        print(output)
                        print()
                
                if "output" in step:
                    print(f"\n{'='*70}")
                    print(f"ğŸ¤– æ™ºèƒ½ä½“å›ç­”:")
                    print(f"{'='*70}")
                    print(step["output"])
                    print()
                    
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ™ºèƒ½ä½“ä½¿ç”¨"""
    
    print("\n" + "="*70)
    print("RAG æ™ºèƒ½ä½“")
    print("   åŸºäº LangChain create_agent")
    print("="*70 + "\n")
    
    # åˆå§‹åŒ–æ™ºèƒ½ä½“
    try:
        agent = SimpleRAGAgent(
            persist_directory="./chroma_db",
            collection_name="database_knowledge",
            model_name="openai/gpt-4o-mini",  # OpenRouter
            temperature=0
        )
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        print("\nğŸ’¡ è¯·å…ˆè¿è¡Œ build_knowledge_base.py æ„å»ºçŸ¥è¯†åº“")
        return 1
    
    # æµ‹è¯•é—®é¢˜åˆ—è¡¨
    test_questions = [
        "å¦‚ä½•æŸ¥è¯¢2025.12.11å‘ç”Ÿè¿˜æ¬¾ä¸”æ‰‹æœºå·éªŒè¯é€šè¿‡çš„å€Ÿæ¬¾ç”¨æˆ·ï¼Œæˆªæ­¢åˆ°æ˜¨å¤©çš„å¾…è¿˜é‡‘é¢ä»¥åŠè¿˜æ¬¾é‡‘é¢ï¼Œè¿˜æ¬¾ç‡"
    ]
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ™ºèƒ½ä½“...\n")
    
    # ä¾æ¬¡æµ‹è¯•æ¯ä¸ªé—®é¢˜
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'#'*70}")
        print(f"# æµ‹è¯• {i}/{len(test_questions)}")
        print(f"é—®é¢˜: {question}")
        print(f"{'#'*70}")
        
        # ä½¿ç”¨æµå¼å¯¹è¯å±•ç¤ºè¿‡ç¨‹
        response = agent.chat(question)
        print(f"å›ç­”: {response}")



if __name__ == "__main__":
    sys.exit(main())

